{
    "embed_dim": 512,
    "num_heads": 8,
    "hidden_dim": 1024,
    "num_layers": 14,
    "max_sequence_length": 512,

    "pretrained_tokenizer": "bert-base-uncased",
    "vocab_size": null,

    "gradient_accumulation_steps": 16,
    "batch_size": 16,
    "num_epochs": 3,

    "warmup_ratio": 0.05,
    "lr": "auto",

    "dataset_name": "BEE-spoke-data/fineweb-1M_longish",
    "dataset_split": "train",
    "dataset_text_field": "text",
    "estimated_tokens_per_epoch": 3500000000,

    "checkpoint_prefix": "./checkpoints/microlm-60m",
    "resume_checkpoint_path": "./checkpoints/microlm-60m-epoch-1-batch-64086.pt",

    "num_workers": 0,
    "pin_memory": true,
    "drop_last": true,
    "save_interval_ratio": 0.1,

    "use_flash_attn": false,
    "flash_attn_dropout": 0.0,

    "generation_max_new_tokens": 500,
    "generation_temperature": 1.0
}
